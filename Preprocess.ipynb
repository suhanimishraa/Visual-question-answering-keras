{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os, argparse\n",
    "import cv2, spacy, numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.externals import joblib\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "word_embeddings = spacy.load('en_vectors_web_lg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model  \n",
    "from keras.layers import *\n",
    "from keras.applications.resnet50 import ResNet50  \n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2 \n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "\n",
    "model_resnet50 = ResNet50(include_top=True)\n",
    "#print(model_resnet50.summary())\n",
    "model_resnet50 = Model(inputs=model_resnet50.input, outputs=model_resnet50.get_layer('avg_pool').output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "\n",
    "\n",
    "def get_image_features_resnet(x):\n",
    "    x = keras.applications.resnet50.preprocess_input(x)\n",
    "    features = model_resnet50.predict(x)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "\n",
    "def get_image_features_inception(x):\n",
    "    x = keras.applications.inception_resnet_v2.preprocess_input(x)\n",
    "    features = model_inception.predict(x)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "\n",
    "\n",
    "def get_image_features_xception(x):\n",
    "    x = keras.applications.xception.preprocess_input(x)\n",
    "    features = model_xception.predict(x)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_features(question):\n",
    "    \n",
    "    \n",
    "\n",
    "    tokens = word_embeddings(question)\n",
    "    question_tensor = np.zeros((1, 30, 300))\n",
    "    for j in range(len(tokens)):\n",
    "        question_tensor[0,j,:] = tokens[j].vector\n",
    "    return question_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pro(image_file_name):\n",
    "    img_path = image_file_name\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img2 = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x1 = image.img_to_array(img2)\n",
    "    x1 = np.expand_dims(x1, axis=0)\n",
    "    r = get_image_features_resnet(x1)\n",
    "    i = get_image_features_inception(x)\n",
    "    x = get_image_features_xception(x)\n",
    "    return r,i,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "\n",
    "import json\n",
    "\n",
    "   \n",
    "train = []\n",
    "test = []\n",
    "imdir= 'train2014/COCO_train2014_%012d.jpg'\n",
    "\n",
    "\n",
    "#print 'Loading annotations and questions...'\n",
    "train_anno = json.load(open('v2_mscoco_train2014_annotations.json', 'r'))\n",
    "\n",
    "\n",
    "train_ques = json.load(open('v2_OpenEnded_mscoco_train2014_questions.json', 'r'))\n",
    "\n",
    "test_ques = json.load(open('v2_OpenEnded_mscoco_test2015_questions.json', 'r'))\n",
    "\n",
    "#subtype = 'train2014'\n",
    "for i in range(len(train_anno['annotations'])):\n",
    "    ans = train_anno['annotations'][i]['multiple_choice_answer']\n",
    "    question_id = train_anno['annotations'][i]['question_id']\n",
    "    image_path = imdir%(train_anno['annotations'][i]['image_id'])\n",
    "    img_id = train_anno['annotations'][i]['image_id']\n",
    "    question = train_ques['questions'][i]['question']\n",
    "\n",
    "    train.append({'ques_id': question_id,'img_id':img_id , 'img_path': image_path, 'question': question, 'ans': ans})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#json.dump(train, open('vqa_raw_train.json', 'w'))\n",
    "#json.dump(test, open('vqa_raw_test.json', 'w'))\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "\n",
    "train = sorted(train, key = lambda i: (i['ques_id']))\n",
    "#train = np.asarray(train)\n",
    "#train = np.squeeze(train)\n",
    "#np.save('train.npy',train)\n",
    "train = train[0:80000]\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "label_encoder_file_name = 'FULL_labelencoder_trainval.pkl'\n",
    "labelencoder = joblib.load(label_encoder_file_name)\n",
    "\n",
    "\n",
    "#labelencoder.classes_[12]\n",
    "mapp = {}\n",
    "mappr = {}\n",
    "\n",
    "for i in range(len(labelencoder.classes_)):\n",
    "  #print(labelencoder.classes_[i],i)\n",
    "  mapp[i] = labelencoder.classes_[i]\n",
    "  mappr[labelencoder.classes_[i]] = i\n",
    "  \n",
    "#mapp[64]\n",
    "#mappr[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "\n",
    "import time\n",
    "import keras\n",
    "\n",
    "\n",
    "\n",
    "imdir= 'train2014/COCO_train2014_%012d.jpg'\n",
    "#word_embeddings = spacy.load('en_vectors_web_lg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "imgfet_res = []\n",
    "imgfet_inc = []\n",
    "imgfet_x = []\n",
    "qfet = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(80000):\n",
    "    try:\n",
    "        mappr[train[i]['ans']]\n",
    "        fet_res,fet_inc,fet_x = pre_pro(imdir%(train[i]['img_id']))\n",
    "        print('img')\n",
    "        u = str(train[i]['question'])\n",
    "        qfet = get_question_features(u)\n",
    "        print('ques')\n",
    "        imgfet_res.append(fet_res)\n",
    "        imgfet_inc.append(fet_inc)\n",
    "        imgfet_x.append(fet_x)\n",
    "\n",
    "        quesfet.append(qfet)\n",
    "        l.append(mappr[train[i]['ans']])\n",
    "        print(i)\n",
    "        end = time.time()\n",
    "        g = (end-start)\n",
    "        #et = tt-g\n",
    "        #print('estimated time : ',end)\n",
    "        print(time.strftime(\"%H:%M:%S\", time.gmtime(g)))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#np.save('imgfet_res.npy',imgfet_res)\n",
    "\n",
    "imgfet_res = np.asarray(imgfet_res)\n",
    "imgfet_res = np.squeeze(imgfet_res)\n",
    "np.save('imgfet_res.npy',imgfet_res)\n",
    "del imgfet_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgfet_inc = np.asarray(imgfet_inc)\n",
    "imgfet_inc = np.squeeze(imgfet_inc)\n",
    "np.save('imgfet_inc.npy',imgfet_inc)\n",
    "\n",
    "del imgfet_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgfet_x = np.asarray(imgfet_x)\n",
    "imgfet_x = np.squeeze(imgfet_x)\n",
    "np.save('imgfet_x.npy',imgfet_x)\n",
    "\n",
    "del imgfet_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qfet = np.asarray(qfet)\n",
    "qfet = np.squeeze(qfet)\n",
    "np.save('quesfet.npy',qfet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(80000):\n",
    "    \n",
    "    \n",
    "    \n",
    "  #fet = get_image_features(imdir%(train[i]['img_id']))\n",
    "  try:\n",
    "    mappr[train[i]['ans']]\n",
    "    l.append(mappr[train[i]['ans']])\n",
    "    print(train[i]['ans'])\n",
    "    \n",
    "  except KeyError:\n",
    "    continue\n",
    "    \n",
    "    \n",
    "print(len(l))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.asarray(l)\n",
    "l = np.squeeze(l)\n",
    "\n",
    "np.save('label.npy',l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
